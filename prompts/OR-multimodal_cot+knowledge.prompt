from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match, get_operation_phase, analyse_audio

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
    get_operation_phase()->str
        Returns the phase of the operation at the time of the current image.
    analyse_audio(query_sound)->bool
        Returns if the queried sound is detected at the timestamp of the image.
    """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image based on a general purpose vision model. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------
        >>> # What is in front of the horse?
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question, simple_relation_query)
    
    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch. Only useful to create a focused image version enclosing multiple objects.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

    def get_operation_phase(self)->str:
        """Returns the operation phase of the timestamp calculated from the current image index. Will resolve non-singular detections internally and
        directly return the final prediction.
        Possible answers are "", "Fallplanung", "RIO-Kontrolle vor OP", "Knochenregistrierung", "Intra-OP Planung", "Intra-OP Knochenvorbereitung", "Abschluss des Falls".

        Examples
        -------
        >>> # In what phase of the operation are we?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     return image_patch.get_operation_phase()
        """
        return get_operation_phase(self.cropped_image)
    
    def analyse_audio(self, query_sound: int)->bool:
        """Returns if the query sound is present at the time. Can only handle specified set of query sounds. 
        Parameters
        -------
        query_sound : str
            One of the following:
                -sawing
                -drilling
                -hammering
                -rustling
                -tool clanking
                -talking
        
        Examples
        -------
        >>> # Is there rustling?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     return bool_to_yesno(image_patch.analyse_audio("rustling"))
        """
        return analyse_audio(query_sound)

"""
INSERT KNOWLEDGE HERE
"""

# Examples of using ImagePatch

# Query:
# Is there drilling?
# Thoughts:
# Drilling produces a distinct sound that the audio analysis model is designed to detect.
# Since the audio model has a positive bias it will sometimes detect a sound when there is none.
# It is therefore necessary to add a second check if the audio model predicts a sound. This can be done using the general purpose vision model.
# As the operating tools can only be used by head surgeon or assistant surgeon, it has to be checked if either of them is performing the action, in this case drilling,
# on the patient. If this check is also positive, the action can be confirmed.
# Code:
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    sound_detected = image_patch.analyse_audio("drilling")
    if sound_detected:
        # either head surgeon or assistant surgeon can be holding the corresponding tool
        head_surgeon_drilling = image_patch.simple_query("Is the head surgeon drilling the patient?")
        assistant_surgeon_drilling = image_patch.simple_query("Is the assistant surgeon drilling the patient?")
        if head_surgeon_drilling == "yes" or assistant_surgeon_drilling == "yes":
            return "yes"
    return "no"

# Query:
# What is the relation between the anesthetist and the operating table?
# Thoughts:
# First, the object detection model has to be queried with the two relevant objects "anesthetist" and "operating table". If not found, ask the general purpose vision model directly.
# If they are both found, an image crop enclosing both of them should be created. Based on this focused view the general purpose vision model is queried.
# Code:
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    anesthetist_patches = image_patch.find("anesthetist")
    operating_table_patches = image_patch.find("operating table")
    if len(anesthetist_patches) == 0 or len(operating_table_patches) == 0:
        return image_patch.simple_query("What is the relation between the anesthetist and the operating table?")
    anesthetist_patch = anesthetist_patches[0]
    operating_table_patch = operating_table_patches[0]
    union_patch = image_patch.crop(min(anesthetist_patch.left, operating_table_patch.left), min(anesthetist_patch.lower, operating_table_patch.lower),\
                                 max(anesthetist_patch.right, operating_table_patch.right), max(anesthetist_patch.upper, operating_table_patch.upper))
    return union_patch.simple_query("What is the relation between the anesthetist and the operating table?")

# Query:
# How many people are there?
# Thoughts:
# For this query, the functionality of the method find() suffices, as it returns all detections of the query object in a list. So find() has to be queried with "people"
# and the length of the list is returned as the final answer.
# Code:
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    person_patches = image_patch.find("person")
    return len(person_patches)

# Query:
# INSERT_QUERY_HERE
# Thoughts: